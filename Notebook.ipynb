{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TEST = pd.read_csv('Xtest.csv')\n",
    "X = pd.read_csv('Xtrain_hgcGIrA.csv')\n",
    "Y = pd.read_csv('Ytrain_yL5OjS4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{1)}$ Pré-traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([X_test,y_test], axis = 1)\n",
    "train = pd.concat([X_train,y_train],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missings = [col for col in train.columns if train[col].isnull().any()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['hour'] = pd.to_datetime(train['hour'], format='%H:%M:%S')\n",
    "train['hour'] = train['hour'].dt.hour\n",
    "\n",
    "test['hour'] = pd.to_datetime(test['hour'], format='%H:%M:%S')\n",
    "test['hour'] = test['hour'].dt.hour\n",
    "\n",
    "X_TEST['hour'] = pd.to_datetime(X_TEST['hour'], format='%H:%M:%S')\n",
    "X_TEST['hour'] = X_TEST['hour'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour les stations on remplace les valeurs manquantes par 0\n",
    "train[cols_with_missings[1:]] = train[cols_with_missings[1:]].fillna(0)\n",
    "test[cols_with_missings[1:]] = test[cols_with_missings[1:]].fillna(0)\n",
    "X_TEST[cols_with_missings[1:]] = X_TEST[cols_with_missings[1:]].fillna(0)\n",
    "\n",
    "#Pour l'heure on prend la partie entière de la médiane\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy = 'median')\n",
    "\n",
    "train['hour'] = imputer.fit_transform(train[['hour']])\n",
    "train['hour'] = train['hour'].astype(int)\n",
    "\n",
    "test['hour'] = imputer.transform(test[['hour']])\n",
    "test['hour'] = test['hour'].astype(int)\n",
    "\n",
    "X_TEST['hour'] = imputer.transform(X_TEST[['hour']])\n",
    "X_TEST['hour'] = X_TEST['hour'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On va maintenant encoder la varible station en utilisant un simple label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "train['station'] = encoder.fit_transform(train['station']).astype(int)\n",
    "test['station'] = encoder.transform(test['station']).astype(int)\n",
    "X_TEST['station'] = encoder.transform(X_TEST['station']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{2)}$ Sélection du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Séparation des variables explicatives et de la variable cible\n",
    "explanatory_varibales = ['station', 'hour', 'p1q0', 'p2q0', 'p3q0', 'p0q1', 'p0q2', 'p0q3']\n",
    "X_train = train.loc[:, explanatory_varibales]\n",
    "X_test = test.loc[:, explanatory_varibales]\n",
    "X_TEST = X_TEST.loc[:, explanatory_varibales]\n",
    "\n",
    "y_train = train.loc[:,'p0q0']\n",
    "y_test = test.loc[:,'p0q0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des différents modèles que nous allons tester\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_absolute_percentage_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'SVR': SVR(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'K Neighbors': KNeighborsRegressor(),\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Random Forest' : RandomForestRegressor()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Procédure d'évaluation des mdèles\n",
    "import numpy as np\n",
    "\n",
    "MAPE = make_scorer(mean_absolute_percentage_error)\n",
    "MAE = make_scorer(mean_absolute_error)\n",
    "\n",
    "def Evaluation(models, X_train, y_train, metric=MAPE):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        score = cross_val_score(model, X_train, y_train, cv=5, scoring=metric)\n",
    "        results[name] = {\n",
    "            'mean_score': score.mean(),\n",
    "            'std_score': score.std()\n",
    "        }\n",
    "        print(f\"{name}: {results[name]['mean_score']:.2f} +/- {results[name]['std_score']:.2f}\")\n",
    "        break\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR: 0.05 +/- 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SVR': {'mean_score': 0.0470382056938425,\n",
       "  'std_score': 0.00010939997219629958}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation(models,  X_train, y_train, metric = MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{3)}$ Optimisation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-12 19:59:20,964] A new study created in memory with name: no-name-0dda9e92-a370-4b51-bf4e-340beae83e71\n",
      "[I 2023-11-12 19:59:44,824] Trial 2 finished with value: 0.018288788763413028 and parameters: {'n_estimators': 159, 'learning_rate': 0.10629127546981113, 'max_depth': 5, 'min_samples_split': 10}. Best is trial 2 with value: 0.018288788763413028.\n",
      "[I 2023-11-12 19:59:53,755] Trial 3 finished with value: 0.014155238988268475 and parameters: {'n_estimators': 108, 'learning_rate': 0.14721131878892732, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 3 with value: 0.014155238988268475.\n",
      "[I 2023-11-12 20:00:03,824] Trial 4 finished with value: 0.023915766745867845 and parameters: {'n_estimators': 317, 'learning_rate': 0.01995058723840638, 'max_depth': 4, 'min_samples_split': 9}. Best is trial 3 with value: 0.014155238988268475.\n",
      "[I 2023-11-12 20:00:04,449] Trial 0 finished with value: 0.014304712331838545 and parameters: {'n_estimators': 156, 'learning_rate': 0.14625705818608764, 'max_depth': 8, 'min_samples_split': 8}. Best is trial 3 with value: 0.014155238988268475.\n",
      "[I 2023-11-12 20:00:20,633] Trial 1 finished with value: 0.017908259601905046 and parameters: {'n_estimators': 445, 'learning_rate': 0.11750481857049777, 'max_depth': 4, 'min_samples_split': 7}. Best is trial 3 with value: 0.014155238988268475.\n",
      "[I 2023-11-12 20:00:27,844] Trial 5 finished with value: 0.01550813822050583 and parameters: {'n_estimators': 395, 'learning_rate': 0.280860562156866, 'max_depth': 5, 'min_samples_split': 9}. Best is trial 3 with value: 0.014155238988268475.\n",
      "[I 2023-11-12 20:01:02,088] Trial 8 finished with value: 0.014695990082847563 and parameters: {'n_estimators': 361, 'learning_rate': 0.2273329493678483, 'max_depth': 7, 'min_samples_split': 9}. Best is trial 3 with value: 0.014155238988268475.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna import trial\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10)\n",
    "    }\n",
    "\n",
    "    # Instanciation et entraînement du modèle\n",
    "    model = GradientBoostingRegressor(**param, random_state=0)\n",
    "    model.fit(X_train.iloc[:,1:], y_train)\n",
    "    y_pred = model.predict(X_test.iloc[:,1:])\n",
    "\n",
    "    error = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    return error\n",
    "\n",
    "study = optuna.create_study()  \n",
    "study.optimize(objective, n_trials=20, n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=6, state=1, values=[0.08763875388976404], datetime_start=datetime.datetime(2023, 11, 12, 0, 27, 53, 833251), datetime_complete=datetime.datetime(2023, 11, 12, 0, 28, 12, 382688), params={'n_estimators': 190, 'learning_rate': 0.22888401338267433, 'max_depth': 3, 'min_samples_split': 8}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=500, log=False, low=100, step=1), 'learning_rate': FloatDistribution(high=0.3, log=False, low=0.01, step=None), 'max_depth': IntDistribution(high=10, log=False, low=3, step=1), 'min_samples_split': IntDistribution(high=10, log=False, low=2, step=1)}, trial_id=6, value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 190,\n",
       " 'learning_rate': 0.22888401338267433,\n",
       " 'max_depth': 3,\n",
       " 'min_samples_split': 8}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur finale sur le jeu de test: 0.09\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(**params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'Erreur finale sur le jeu de test issue de train_test_split: {mean_absolute_error(y_test, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{4)}$ Entrainement sur le jeu tout entier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.concat([X_train,X_test], axis = 0)\n",
    "y_train_full = pd.concat([y_train,y_test], axis = 0)\n",
    "\n",
    "model = GradientBoostingRegressor(**params)\n",
    "model.fit(X_train_full, y_train_full)\n",
    "predictions = model.predict(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soumission = pd.DataFrame({\"p0q0\" : predictions })\n",
    "\n",
    "soumission.index = np.arange(1,len(soumission)+1)\n",
    "display(soumission)\n",
    "soumission.to_csv(\"soumission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
